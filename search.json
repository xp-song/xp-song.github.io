[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xiao Ping Song",
    "section": "",
    "text": "Hello, I’m Xiao Ping. I work on developing metrics and predictive software for city planning and sustainability reporting. My research and teaching focus on applied machine learning and geospatial techniques.\nAside from work, I find creative outlets in music, and in looking for ways to bring the family out for our next adventure."
  },
  {
    "objectID": "posts/zoom-drum-lessons/index.html",
    "href": "posts/zoom-drum-lessons/index.html",
    "title": "Zoom with Drums",
    "section": "",
    "text": "Recent measures to contain the coronavirus outbreak have left many local businesses reeling. I’ve been teaching drums part-time at My Drum School (MDS), but as of tommorrow, all centres will have to shut down their physical premises.\nThankfully, our school has already been scrambling to move to online lessons since last week. The team has been working hard to set up new equipment and release how-to videos, web resouces and online syllabus material. The complete integration of all these materials and new workflows (in just a few days!) within the MDS mobile app is nothing short of amazing.\nDuring my first few online lessons, I got to experience first-hand the difficulty in playing to music/click tracks, especially with regard to sound quality. After some experimentation, I was inspired to make a couple of video tutorials showing how these issues may be addressed. Hopefully this will help teachers and students improve their online lesson experience.\n\nPart 1:\n\n\n\n\n\nPart 2:\n\n\n\n\n\n\nNote: For an introductory video on how to set-up for online lessons, see the video released by My Drum School here."
  },
  {
    "objectID": "posts/street-trees/index.html",
    "href": "posts/street-trees/index.html",
    "title": "The performance of city trees",
    "section": "",
    "text": "Trees are often the largest components of landscape greenery, and can help enhance the environmental quality of city landscapes. For example, trees can lower temperatures by providing shade, and reduce the risk of flooding by intercepting rainfall. Such benefits accumulate across wider areas, producing substantial effects that can help make cities more liveable and adaptable to climate change. Trees are thus a form of ‘natural capital’ that produce value for people.\nMany cities have started to assess the status and health of these natural capital assets, which is an important step to incorporate the environment into holistic, national-scale planning. The downstream effects associated with trees often rely on their size and structure, which varies between species and changes over time. For practical purposes, however, measuring these multiple dimensions is usually not possible. Such values may have to be estimated indirectly using allometric relationships between the quantities of interest and easily-measured parameters such as a tree’s trunk diameter.\nAs part of my PhD work, I developed the R package allometree to build such allometric relationships, as well as a prototype web application demonstrating how the package may be used. If you’re interested, you may check out the following publication:\nRapid advances in remote sensing may soon reduce the manual effort required for data collection, and shift research and development toward real-time monitoring for tree management. However, systems and workflows will need to evolve to take advantage of such innovations. Work is needed to streamline data pipelines for analyses, and to integrate multiple datasets and objectives effectively for decision-making."
  },
  {
    "objectID": "posts/street-trees/index.html#references",
    "href": "posts/street-trees/index.html#references",
    "title": "The performance of city trees",
    "section": "References",
    "text": "References\n\nSong, X. P., Lai, H. R., Wijedasa, L. S., Tan, P. Y., Edwards, P. J., Richards, D. R. (2020), Height–diameter allometry for the management of city trees in the tropics. Environmental Research Letters, 15, 114017. https://doi.org/10.1088/1748-9326/abbbad\nSong, X. P., Tan, P. Y., Edwards, P. J., Richards, D. R. (2018). The economic benefits and costs of trees in urban forest stewardship: A systematic review. Urban Forestry & Urban Greening, 29, 162–170. https://doi.org/10.1016/j.ufug.2017.11.017\nSong, X. P., Richards, D. R., Edwards, P. J., Tan, P. Y. (2017). Benefits of trees in tropical cities. Science, 356 (634), 1241. https://doi.org/10.1126/science.aan6642"
  },
  {
    "objectID": "posts/intro2r-spatial/index.html",
    "href": "posts/intro2r-spatial/index.html",
    "title": "Analysing spatial patterns of the landscape",
    "section": "",
    "text": "In landscape ecology, we study interactions between organisms and their surrounding environment. The physical landscape is often quantified using ‘landscape metrics’, for further analyses alongside other sources of data.\nMy recent lectures are focused on introducing such concepts to landscape architects. While I’ve used FRAGSTATS and other GIS software for teaching in the past, I’ve always struggled with compatibility/licensing issues that just made the whole process really cumbersome.\nRecently, I came across this R package called landscapemetrics—I was blown away. I’ve always wanted to introduce people to spatial analyses in R, and to show how a programmatic, reproducible workflow in R can be an excellent alternative to conventional software. This was the tipping point for me… I decided to give it a shot!\nThis post provides a preview of the workshop content. The workshop is meant to be a follow-up lesson to the Introduction to R series I’ll be conducting next semester."
  },
  {
    "objectID": "posts/intro2r-spatial/index.html#workshop-outline",
    "href": "posts/intro2r-spatial/index.html#workshop-outline",
    "title": "Analysing spatial patterns of the landscape",
    "section": "Workshop outline",
    "text": "Workshop outline\n\n\nWhy analyse spatial patterns?\nLandscape ecology: Conceptual models\nLand cover classification\nLandscape metrics\n\n\nI’ve uploaded the slides and data on Github, so that anyone interested to try out the analysis for themselves will be able to do so. If you’re interested in geospatial analysis, check it out!"
  },
  {
    "objectID": "posts/intro2r-spatial/index.html#slide-deck",
    "href": "posts/intro2r-spatial/index.html#slide-deck",
    "title": "Analysing spatial patterns of the landscape",
    "section": "Slide deck",
    "text": "Slide deck\n\n\n\n\n\n\n\n\n\n\nThis post is also shared on R-bloggers.com."
  },
  {
    "objectID": "posts/city-landcover-change/index.html",
    "href": "posts/city-landcover-change/index.html",
    "title": "Changes in a city’s land cover over time",
    "section": "",
    "text": "As part of a research project to develop biodiversity indices for city planning, I’ve had to quantify different components of the landscape using satellite data. One of these components is land cover, from which other metrics can be further derived. So far, this has been done for Sentinel-2 and Skysat data. Here is a brief summary of the steps and template R code used to derive land cover classes from publicly-available Sentinel-2 imagery. We’re open to collaborate and explore new applications in remote sensing, so we’d love to hear from you if you have any feedback or ideas!\nFirst, load the required R packages:\nAnd here’s the raw shape file for our area of interest:"
  },
  {
    "objectID": "posts/city-landcover-change/index.html#calculate-spectral-indices",
    "href": "posts/city-landcover-change/index.html#calculate-spectral-indices",
    "title": "Changes in a city’s land cover over time",
    "section": "Calculate spectral indices",
    "text": "Calculate spectral indices\nTo download Sentinel-2 images, we can use the R package sen2r to programatically download the satellite data within a specified date range. It also allows us to run pre-processing steps such as cloud masking, atmospheric correction and the calculation of spectral indices.\n\n# get search parameters\njson_path <- \"<PATH TO YOUR JSON FILE>\"\n# you can create this file by running 'sen2r()', then using the graphical user interface to specify & save your parameters (e.g. max cloud cover per image, etc.)\n\n\n# download\nout_paths <- sen2r(\n  param_list = json_path,\n  extent_as_mask = TRUE, # mask the image based on your supplied shape file\n  list_rgb = \"RGB432B\" # output RGB image\n  )\n\nFor each data type (e.g., spectral index), we can combine all raster images captured within the specified date range by averaging the pixel values across files (thus forming an image mosaic). This allows us to avoid relying on any one image for our analysis, and to deal with missing data (e.g., due to high cloud cover) during the period of interest. Depending on the data type, we can scale the values and remove outliers prior to forming the image mosaic. You might also want to consider parallelising the code if there are many files. Run the following code for each data type:\n\nfilepaths <- \"<PATHS TO YOUR PROCESSED FILES>\"\n\nimages <- lapply(filepaths, rast) # import rasters as a list\nmosaic <- do.call(terra::mosaic, c(images, list(fun = \"mean\")))\n\n# export mosaic\nwriteRaster(mosaic, \"<MOSAIC FILE NAME>.tif\",\n            wopt = list(gdal=c(\"COMPRESS=LZW\")), # compress output\n            overwrite = TRUE)"
  },
  {
    "objectID": "posts/city-landcover-change/index.html#classify-land-cover",
    "href": "posts/city-landcover-change/index.html#classify-land-cover",
    "title": "Changes in a city’s land cover over time",
    "section": "Classify land cover",
    "text": "Classify land cover\nAt this point, we have a single image mosaic (raster) for each spectral index. While the continuous values from these rasters may be used directly in analyses, there may be instances were we want to work with discrete classes of land cover. One method is to separate pixels into one of two classes (e.g., vegetated or non-vegetated; water or land), based on an adaptively derived threshold value. For example, we use Otsu’s thresholding (Otsu, 1979), which tends to outperform other techniques in terms of stability of results and processing speed, even with the presence of > 2 peaks in the histogram of pixel values (Bouhennache et al., 2019; see figure below). This may be implemented using the otsu() function in library(EBImage):\n\nthreshold_value <- EBImage::otsu(mosaic, \n                                 range = c(-1, 1), # histogram range\n                                 levels = 256) # depends on image bit-depth\n\nclassified <- mosaic # duplicate\n\nclassified[mosaic < threshold_value] <- 0 # assign value of 0 for pixels below threshold (e.g. non-vegetated)\nclassified[mosaic >= threshold_value] <- 1 # assign value of 1 for pixels above threshold (e.g. vegetated)\n\nAs an example, the following figure shows the distribution of the Normalized Difference Vegetation Index (NDVI) values of a raster image. The NDVI is a measure of healthy green vegetation, based on the tendency of plants to reflect NIR & absorb red light. It ranges from -1 (non-vegetated) to 1 (densely vegetated). Pixels that fall within the range of different threshold values (vertical lines) may be classified into discrete land cover types. If we do this for multiple date ranges, we can examine differences between the two. For example, in our project, we are currently comparing image mosaics captured during 2016–2019 (Survey Round One) and those captured during 2019–2022 (Survey Round Two). Each spectral index can be processed in different ways, and often have different threshold values if they are used for land classification. For example, there are numerous other vegetation indices (e.g., NDRE, ARVI), as well as spectral indices used to classify water (e.g., NDWI) and built (e.g., NDBI) cover.\n\n\n\n\n\n\nFigure 2: Distribution of NDVI values across Singapore in Survey Round One (light green bars, dashed vertical lines) and Two (dark green bars, solid vertical lines). Vegetation was classified as pixel with values > 0.35 for Round One and > 0.36 for Round Two. Dense vegetation was classified as pixels with values > 0.62 for Round One and > 0.66 for Round Two, based on a second round of Otsu’s thresholding after the first round of classification."
  },
  {
    "objectID": "posts/city-landcover-change/index.html#accuracy-assessments",
    "href": "posts/city-landcover-change/index.html#accuracy-assessments",
    "title": "Changes in a city’s land cover over time",
    "section": "Accuracy assessments",
    "text": "Accuracy assessments\nHow do we know that the land cover classes we have derived are accurate? Some form of ground-truthing is required. In our research project, on-site mapping has been performed at sampling points over the years.\n\n\n\n\nFigure 3: Screenshot showing vegetation derived from on-site surveys and satellite imagery at sampling points in Punggol, Singapore.\n\n\n\nThe next figure shows a basic comparison of land cover area between surveyed (x-axes) and satellite (y-axes) data. As we can see, there are positive relationships between the two (particularly for vegetation cover), but the relatively large root-mean-square errors (RMSE) show that low resolution satellite imagery does have its limitations.\n\n\n\n\nFigure 4: Area of (a) vegetation, (b) built and (c) water cover derived from Sentinel-2 compared with on-site surveys at sampling points."
  },
  {
    "objectID": "posts/city-landcover-change/index.html#summarise-per-zone",
    "href": "posts/city-landcover-change/index.html#summarise-per-zone",
    "title": "Changes in a city’s land cover over time",
    "section": "Summarise per zone",
    "text": "Summarise per zone\nNow that we have land cover classified during different periods of time, one way to compare differences in land cover is to summarise them according to the zones used in city planning. Spectral indices (whether classified or not) can be summarised within each zone, to allow comparisons to be made between these planning units.\nHere’s a map showing the proportional area and change in the basic types of land cover within municipal subzones in Singapore. The image quality, NDVI and classified vegetation for both survey rounds are also viewable. Note that the reported amount of NA pixels have been scaled up substantially (×1015) for the purpose of visualisation, so the image quality is actually pretty good (i.e., low cloud cover). This means that differences between survey rounds are unlikely to be due to differences in image quality. You may toggle the visibility of the different layers within the map.\n\n\n\nBased on this comparison of satellite images captured between Survey Round One and Two, we find that:\n\nSparse vegetation increased within the Central Water Catchment and offshore islands. However, dense vegetation decreased substantially within these areas too.\nWater cover at the eastern (North Eastern Islands) and western (Tuas View Extension) tips of Singapore decreased, but increased at north-western areas, Jurong Island and the Central Water Catchment.\nBuilt cover decreased substantially within Jurong Island and along the south-western coast of Singapore.\n\n\nWhat factors have contributed to land cover changes during this period of time? What other interesting patterns do you see? Feel free to reach out to us if you are interested to collaborate (P.S. We are also hiring!).\n\nThis post is also shared on R-bloggers.com."
  },
  {
    "objectID": "posts/kashiwanoha/index.html",
    "href": "posts/kashiwanoha/index.html",
    "title": "‘Kashiwanoha Smart City’ design workshop",
    "section": "",
    "text": "I recently took part in a design workshop held from 17–25 Feb 2017 at the Center for Environment, Health and Field Sciences, Chiba University, Japan. It was conducted as part of a collaboration between Tsinghua University, National University of Singapore, and Chiba University. Here’s the output that our team produced for local officials at Kashiwanoha city."
  },
  {
    "objectID": "posts/kashiwanoha/index.html#design-objectives",
    "href": "posts/kashiwanoha/index.html#design-objectives",
    "title": "‘Kashiwanoha Smart City’ design workshop",
    "section": "Design objectives",
    "text": "Design objectives\n\nAssess site conditions in the context of the ‘Kashiwanoha Smart City’ concept and vision. Include the current coverage and distribution of green spaces, how such spaces are used, environmental constraints faced in urban greening, the needs of people, relationships between the site and adjacent neighbourhoods, etc.\nIdentify and articulate key issues that can be addressed through planning and design, keeping in mind current encumbrances.\nDevelop a conceptual design for how green spaces can be improved, added or amalgamated to deliver more functions, either in improving environmental performance (biophysical or biodiversity), or to better meet the needs of people."
  },
  {
    "objectID": "posts/kashiwanoha/index.html#slide-deck",
    "href": "posts/kashiwanoha/index.html#slide-deck",
    "title": "‘Kashiwanoha Smart City’ design workshop",
    "section": "Slide deck",
    "text": "Slide deck"
  },
  {
    "objectID": "posts/kashiwanoha/index.html#poster",
    "href": "posts/kashiwanoha/index.html#poster",
    "title": "‘Kashiwanoha Smart City’ design workshop",
    "section": "Poster",
    "text": "Poster"
  },
  {
    "objectID": "posts/urban-agriculture/index.html",
    "href": "posts/urban-agriculture/index.html",
    "title": "Feasibility of urban farming in compact cities",
    "section": "",
    "text": "Food security is emerging as a serious threat in many parts of the world. In cities, common strategies to improve the resilience of food supplies are to diversify the sources of food, and to optimise local production. In compact cities where land is scarce, vertical and rooftop farming have been explored as alternatives to conventional agriculture. However, the success of such measures rely on their environmental, social and economic feasilibility within the local context.\nMy Honors Thesis assessed the suitability of light conditions along the vertical surfaces of buildings in Singapore, a dense and compact city in the tropics. These conditions were compared against the light requirements of vegetable crops that require high amounts of light, and that form a significant proportion of the staple diet in many Asian countries. Plant physiological variables such as dark respiration (Rd), light compensation point, light saturation point, photosynthetic capacity (Amax) and quantum yield (Φ) were derived. These were used to calculate plant light requirements, or the ‘Daily Light Integral’, which ranged from 10–30 mol m-2 day-1. Depending on the building height, orientation and configuration, light conditions along vertical surfaces ranged from 2–35 mol m-2 day-1."
  },
  {
    "objectID": "posts/urban-agriculture/index.html#references",
    "href": "posts/urban-agriculture/index.html#references",
    "title": "Feasibility of urban farming in compact cities",
    "section": "References",
    "text": "References\nSong, X. P., Tan, P. Y., Tan, H. T. W. (2018). Assessment of light adequacy for vertical farming in a tropical city. Urban Forestry & Urban Greening, 29, 49–57. https://doi.org/10.1016/j.ufug.2017.11.004"
  },
  {
    "objectID": "posts/trackchange-word/index.html",
    "href": "posts/trackchange-word/index.html",
    "title": "How to clean up ‘tracked changes’ in Word without going insane",
    "section": "",
    "text": "If you’ve ever had to coordinate the writing of a document with multiple authors, you’ll probably understand the pain of handling everyone’s comments and edits. Once that’s finally done, it’s often useful to highlight all changes made to the original document. This is common practice in academic writing, for example, when re-submitting a revised manuscript after a round of review.\nHowever, most journals don’t accept documents with Microsoft Word’s ‘tracked changes’. I mean… who wants to read through a jungle of strikethroughs, comment bubbles and rainbow-colored text? They want a nice, clean document without the mess. To show changes from the original document, highlighted text or a different font color would be acceptable at most.\nSo, I did some searching online, and found some macros to do just that. I really wish I’d discovered this earlier, rather than manually formatting those texts…\nThe following macro accepts and highlights all changes in yellow. Other highlight colors can be found here, in replacement of WdYellow.\nIf you’d rather change the font color, you can use a slightly different version shown below. Different font colors can also be assigned based on the RGB color code (e.g. RGB(0, 0, 255)), under the field ‘myRange.Font.Color’."
  },
  {
    "objectID": "posts/trackchange-word/index.html#references",
    "href": "posts/trackchange-word/index.html#references",
    "title": "How to clean up ‘tracked changes’ in Word without going insane",
    "section": "References",
    "text": "References\n\nhttps://cybertext.wordpress.com/2018/11/22/word-apply-a-highlight-to-all-tracked-changes/\nhttps://superuser.com/questions/813428/convert-tracked-changes-to-highlighted\nhttps://arbitweb.wordpress.com/2011/02/23/macro-to-highlight-track-changes-in-word/"
  },
  {
    "objectID": "posts/hello/index.html",
    "href": "posts/hello/index.html",
    "title": "Hello",
    "section": "",
    "text": "Having seen many academic CVs and personal websites online, I thought I’d have a go at building a website. I must say, it got really interesting and I decided to take the deep dive… hopefully this’ll help build some online visibility and get my work out there. If you’re also interested in building a website, check out Alistair Bailey’s “Building a website using blogdown in R”. At first I tried to use Jekyll but changed my mind after reading this post. I used the two-repository approach to link my website to GitHub pages, following the workflow by Tyler Clavelle.\nAs for blogging, I think it’s a great way to document the little things I’ve discovered or ideas I’ve had. Blogs have become a go-to for me when seeking answers to various questions (just like building this website), and I think it’ll be nice to contribute to this resource base as well. At the very least, future-me will be happy to have something to refer to when I hit the same obstacle down the road. It’s probably difficult to assign a consistent theme to my blog posts, but expect ramblings about data science, productivity hacks, writing, the environment, design, music…\nFinally, I think websites and blogs are also a refreshing alternative to writing long, academic pieces. It’s often a challenge to make my research relatable to people I talk to, and I feel like what I say doesn’t always do justice to the huge effort put in. Most people aren’t really that interested in the technical details (even my wife! But she tries really hard <3), and digital media definitely helps with science communication. Hopefully you will find the content here interesting and useful."
  },
  {
    "objectID": "posts/biodivercity/index.html",
    "href": "posts/biodivercity/index.html",
    "title": "Biodiversity in cities: How can we assess the ‘performance’ of urban developments?",
    "section": "",
    "text": "Current industry practices\nEnvironmental impact assessments are commonly used to assess the impact of new urban developments on biodiversity, and serve to protect natural areas through legislation. In cities such as Singapore, independent consultancies often conduct the assessments and produce reports that are used as points of reference when engaging stakeholders (e.g., government agencies, nature groups) and the general public.\nAs a part of these assessments, on-site surveys of plants and animals are conducted within the area slated for development. These opportunistic records can provide a general picture of biodiversity and potential ways to mitigate environmental impact. However, the recommendations provided tend to be qualitative and too coarse for planning at fine spatial scales (see examples in Fig. 1). In current practice, there is no way to quantitatively scrutinise between proposed design scenarios, and to compare between present and future ‘performance’.\n\n\n\n\n\n\nFigure 1: Recommendations to mitigate the impact of urban development on biodiversity in a consultancy report (Source: AECOM, 2022).\n\n\n\n\n\n\n\n\n\nA predictive approach is needed\nPredictive spatial modelling can address the shortcomings of opportunistic sampling, and is able to assess biodiversity at spatial scales required to inform planning decisions (0.1–100 hectares). For example, species distribution modelling (SDM)1 is a technique that can be used to predict the distribution of a species across geographic space and time, based on environmental conditions such as climate and the physical landscape (Fig. 2). Such SDM frameworks have the potential to provide much better rigour and spatial precision if integrated into the urban development process.\n\n\n\n\n\n\nFigure 2: How species distribution modelling (SDM) generally works (Source: Damaris Zurell, 2020).\n\n\n\n\n\n\nOne limitation of SDMs, however, is their focus on only a single species of interest. Information about the number of species (species richness) observed at a location are not considered. For instance, natural forests may support a lot more species (high species richness) each in greater numbers (high species abundances) compared to urban areas (see Fig. 3). However, SDMs would only convey the probability of occurrence for a chosen species (e.g., habitat suitability map in Fig. 2). While SDMs can be applied to a ‘keystone’ species2, there are challenges in identifying such species3 and ensuring that the chosen species accurately represents the ‘total biodiversity’ of an urban area.\n\n\n\n\n\n\nFigure 3: Illustration showing the difference between species richness and species abundance.\n\n\n\n\n\n\nCommunity structure is another aspect of biodiversity that is still an active area of research, which SDMs do not represent well. While it is possible to combine multiple SDMs4 to produce a community-level model, the diversity of species communities between different areas (Beta diversity; see Fig. 4) is not represented in such models. For example, two urban regions may both have the same total number of species (Gamma diversity; see Fig. 4), but the presence of large water bodies in one may result in diverse communities of water-loving species that can not be found elsewhere. SDMs are not able to highlight the presence of such distinct communities (e.g., Beta diversity map in Fig. 5), which is crucial when prioritising areas for conservation and urban development.\n\n\n\n\n\n\nFigure 4: Gamma (total) diversity across a larger region is composed of Alpha (local) diversity or species richness at single sites, as well as the Beta (community) diversity representing the differences in species compositions between sites.\n\n\n\n\n\n\n\n\n\nFilling the gap in current methods\nAs part of a research project, our team has been developing methods to incorporate these missing elements (e.g., Alpha, Beta, and Gamma diversity) into predictive spatial modelling of biodiversity. We’ve also been working on an R package biodivercity which will allow users to develop and apply such models for their own use cases, and validate model results based on data that they collect. Our method assesses the habitat suitability of landscapes based on their physical characteristics (e.g. spatial patterns of land cover from satellite imagery & LiDAR data, built elements from OpenStreetMap). However, instead of examining the effect of landscapes on individual species, we instead examine their effect on four major animal groups (birds, butterflies, odonates and amphibians) found in Singapore (Fig. 5).\n\n\n\n\n\n\nFigure 5: Broad overview of the data workflow for a chosen animal group (e.g., birds). The Alpha diversity heat map represents the number of species, while the Beta diversity colour map represents unique species communities within a given area.\n\n\n\n\n\n\nIf models are built using remotely sensed landscape data, we can easily predict the diversity of each animal group across time and geographical space (Fig. 5). For example, the interactive map below shows the Alpha (local) diversity of odonates predicted across all subzones5 in Singapore during the year 2020, at a coarse pixel resolution of 100 hectares. Depending on the level of detail required, the pixel resolution can be adjusted accordingly (e.g., 0.1 hectares).\n\n\n\nPixel values can be subsequently summarised within the zones used in city planning, to allow comparisons to be made between these planning units (Fig. 5). The resulting distribution of the summarised values can subsequently be used to compare the ‘performance’ of each planning unit relative to others in the city, or to a set a benchmark/target for the desired level of ‘performance’ (Fig. 6). For example, subzones in Singapore could be benchmarked against the mean of the distribution, as shown below:\n\n\n\n\n\n\nFigure 6: Histogram showing the distribution of values for the average number of odonate species (Alpha diversity) per pixel within each of the 332 subzones in Singapore. Subzones were assigned an arbitrary score of -2 to 2 based on standard deviations from the mean (i.e., performance of the ‘average’ subzone).\n\n\n\n\n\n\nIf spatial predictions were made for multiple snapshots in time, benchmarking could be based on whether the average pixel value for a particular planning unit increases or decreases between two time periods (Fig. 5). For example, if ‘no net loss’ in biodiversity is set as a target, a negative score could be assigned if the average pixel value is reduced, while a positive score could be assigned if the average pixel value increases.\nFinally, it is worth noting that our method allows full customisation of both the pixel size and boundaries within which to summarise the pixel values. This provides flexibility according to the level of analysis (e.g., geographical scale) required by the user. By summarising pixel values within zones used in city planning, animal diversity may be assessed alongside other indices also summarised at the level of these planning units, thus providing a more comprehensive view of components related to biodiversity and beyond (Fig. 5).\n\n\n\n\nBiodiversity in the future\nLandscape data from remotely sensed sources allow biodiversity to be monitored in the past and present. However, there is also a need to assess future urban developments, for instance, to see if proposed designs can effectively mitigate the loss of biodiversity. But since such landscapes do not exist, snapshots of remotely sensed data can not be used. It is therefore important to carefully consider data compatibility between these different use cases when building and using the predictive models.\nUrban design and planning involves the consideration of multiple design scenarios. Manually generated landscape elements (e.g., vector data for vegetation and water) may be produced from prospective designs, but the format and types of such data must be compatible with those used in the predictive models. For instance, when selecting landscape predictors to build the models, land cover classification as discrete rasters would be more compatible with manually generated data, compared to continuous rasters that cannot be feasibly calculated (e.g., spectral indices such as NDVI). Vegetation generated in design scenarios can be rasterized into discrete land cover-types (Fig. 7), and used to replace the remotely sensed data within regions of interest (Fig. 8). Such amendments to landscape data can be made across a site slated for urban development, and then used to make spatial predictions for that particular design scenario (see maps in Fig. 5).\n\n\n\n\n\n\nFigure 7: Example showing how manually generated vector data (points, polygons) of vegetation can be converted to a classified raster of vegetation types used in the predictive models.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Example showing how a classified raster of remotely sensed vegetation can be amended with the manually generated vector data (rasterised). The dark green areas represent canopy cover, while the light green areas represent short vegetation.\n\n\n\n\n\n\nWhile such data conversions may allow similar predictors (and hence models) to be used for different use cases, it should be noted that potential mismatches between different data sources may result in inaccurate predictions. For instance, the level of detail in design scenarios may not include the exact locations of planted trees, and their estimated canopy projection areas may vary greatly from reality after planting. Furthermore, the remotely sensed data represents a top-down view of the landscape, and the effect of multi-tiered planting is not accounted for within the landscape predictors. Collaboration between researchers and practitioners is needed to ensure that model workflows align with the data formats and outputs used in design practice, and that suitable methods are used to ensure that artificially generated datasets are both compatible and accurate to reality after implementation.\n\n\n\n\nSumming it up\nEnvironmental impact assessments help keep governments and companies accountable as they embark on urban development projects. However, current methods do not provide the level of precision required to make quantitative comparisons between places and across time, especially into the future. We also need a much higher level of nuance when prioritising areas for development/conservation, in terms of the number (Alpha diversity) and communities (Beta diversity) of species spatially distributed across the landscape. We will soon be releasing the first version of our R package biodivercity, which we hope will contribute to the larger toolbox of methods used to assess biodiversity in cities. Stay tuned!\n\n\n\n\n\nAcknowledgements\nThis blog post showcases some of the work undertaken in a research project to develop a biodiversity index for residential towns. It was funded from 2016–2022 under the Singapore Ministry of National Development Research Fund, awarded to the National University of Singapore in partnership with the Singapore Housing & Development Board. The lead investigator is Dr. Chong Kwek Yan, with co-investigators Dr. Hugh Tan and Dr. Darren Yeo. The working team includes Justin Nai, Edwin Tan, Hong Jhun Sim, Rachel Lee, and other members of the field team.\n\nThis post is also shared on R-bloggers.com.\n\n\n\n\n\n\nFootnotes\n\n\nBaker, D. J., Maclean, I. M., Goodall, M., & Gaston, K. J. (2021). Species distribution modelling is needed to support ecological impact assessments. Journal of Applied Ecology, 58(1), 21-26.↩︎\nBond, W. J. (1994). Keystone species. In Biodiversity and ecosystem function (pp. 237-253). Springer, Berlin, Heidelberg.↩︎\nPower, M. E., Tilman, D., Estes, J. A., Menge, B. A., Bond, W. J., Mills, L. S., … & Paine, R. T. (1996). Challenges in the quest for keystones: identifying keystone species is difficult—but essential to understanding how loss of species will affect ecosystems. BioScience, 46(8), 609-620.↩︎\nSchmitt, S., Pouteau, R., Justeau, D., De Boissieu, F., & Birnbaum, P. (2017). ssdm: An r package to predict distribution of species richness and composition based on stacked species distribution models. Methods in Ecology and Evolution, 8(12), 1795-1803.↩︎\nGovernment of Singapore (2020). Master Plan 2019 Subzone Boundary (No Sea). data.gov.sg. Released under the terms of the Singapore Open Data Licence version 1.0.↩︎\n\nCitationBibTeX citation:@misc{x.p.2022,\n  author = {Song, X. P. and Tan, E. Y. W. and Lee, S. K. R. and Sim, H.\n    J. and Nai, J. and Chong, K. Y.},\n  title = {Biodivercity: {An} {R} Package for Spatial Assessment of\n    Biodiversity Across City Landscapes},\n  date = {2022},\n  url = {https://xp-song.github.io/posts/biodivercity},\n  doi = {10.5281/zenodo.7410414},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSong, X. P., Tan, E. Y. W., Lee, S. K. R., Sim, H. J., Nai, J., and\nChong, K. Y. 2022. “Biodivercity: An R Package for Spatial\nAssessment of Biodiversity Across City Landscapes.” https://doi.org/10.5281/zenodo.7410414."
  },
  {
    "objectID": "posts/home2park/index.html",
    "href": "posts/home2park/index.html",
    "title": "Trying to fight cabin fever? The types of parks near your home matters",
    "section": "",
    "text": "The COVID-19 pandemic is changing the way we work and play1. As more people work remotely from home, visits to local parks have surged as people look for ways to stay active, find solace and quench their thirst for adventure2. Such opportunities for leisure and recreation play an important part in people’s physical and psychological well-being3.\nNot all parks are created equal. For example, people seeking solace may be drawn to waterfront or nature parks with open or tranquil landscapes4. For others who love adventure (like myself), bike trails are great to break a sweat while having fun with friends. But most of the bike trails in Singapore5 are really hard to get to from where I live (not to mention figuring out bike transport). So, instead of heading out for some adventure, I tend to visit the open field and playground closest to home, going out for short walks with my son (still waiting for my next adrenaline fix!).\nIn city planning, park provision is typically measured by summarising the park area within a given region6. Beyond the area of parks, however, there is a need to characterise the wide variety of parks that serve different groups of people. Understanding such nuances in park access can benefit both residents and city planners, for instance, when considering the location of a new home, or when planning for new parks in the city.\nOur new R package home2park provides ways to measure a variety of park features related to recreation such as foot/cycle trails, waterfronts, forests, open spaces, playgrounds and sport/fitness amenities. It includes functions to download such data from OSM. Alternatively, you may supply your own proprietary datasets, or use new data for the purpose of future scenario planning. Summarising these features at each park allows us to make quantitative comparisons between parks. Some examples are shown below for the city of Singapore, based on OSM data in the year 2020. For instance, parks with extensive trails provide opportunities for running/wheeled sports:\nOther features such as water and vegetation are associated with visual relief, as well as restorative effects on people’s psychological well-being7. If such data (e.g., satellite imagery) are available, they can also be summarised at each park:\nTo calculate the ‘supply’ of these parks features to homes city-wide, these summarised values per park can then be assigned to each residential building. Since people are less likely to visit parks further away from their homes, a ‘distance decay’ parameter can be included. This reduces the supply value originating from parks further away. The ‘distance decay’ for walking to urban parks was empirically determined in Tu et al.8 to fit a negative exponential curve with a coefficient c value of 0.661 (see home2park package for details). The example below shows the supply of park area to residential buildings in Singapore.\nNotice how the largest parks in Singapore tend to be centrally located, especially since we include informal nature areas (e.g., Central Catchment Nature Reserve). Buildings closer to these huge parks would thus have a much larger ‘supply’ of park area. However, each of the residential buildings would have different numbers of people living in them. A large park next to high-rise apartments would benefit a lot more people compared to low-rise housing. If we take into account the number of residents living within each building, a very different picture emerges!\nThese building-level metrics can subsequently be summarised across larger regions, for example, based on zones used in city planning. Not surprisingly, the supply metric for park area derived from individual buildings is vastly different from conventional metrics used today (examples in Tan and Samsudin9). Feel free to explore these metrics for the provision of park area in the interactive map below.\nIn these unprecedented times, significant changes to human mobility and working environments will require us to rethink land use distribution in the city, particularly for office, residential and public spaces such as parks. Some evidence also point to shifting preferences, for example, toward wilder green areas10. These issues are starting to become a part of the national conversation in Singapore 11, which is important considering that the city has major plans for sustainable development and greening over the next decade12. As part of the Singapore Green Plan 2030, there will be 1,000 ha (more than 1,800 football fields!) more parks and park connectors, and every household will live just a 10-minute walk away from a park13. In view of these major plans, there is a need to move beyond basic summaries of area, and consider the variety of parks features that are important for outdoor recreation. The R package home2park represents a part of our effort to contribute to a more nuanced understanding of outdoor recreation and its spatial provision in cities. Note that the package is still experimental, so do reach out if you would like to contribute to improvements, or to report any bugs."
  },
  {
    "objectID": "posts/home2park/index.html#acknowledgements",
    "href": "posts/home2park/index.html#acknowledgements",
    "title": "Trying to fight cabin fever? The types of parks near your home matters",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI’d like to gratefully acknowledge Kwek Yan for his valuable inputs and help to re-fine these ideas we are working on here, as well as Edwin Tan and Justin Nai for the useful discussions. The analyses shown in this blog post is part of a larger project that investigates the balance of park supply and demand in cities between different groups of people, as well as how the ‘distance decay’ affects their use. Do reach out if you are keen to collaborate on related topics. Finally, to cite home2park or acknowledge its use, you may use the following reference:\n\nSong, X. P., Chong, K. Y. (2021). home2park: An R package to assess the spatial provision of urban parks. Journal of Open Source Software, 6(65), 3609. https://doi.org/10.21105/joss.03609\n\n\n\nThis post is also shared on R-bloggers.com."
  },
  {
    "objectID": "posts/intro2r/index.html",
    "href": "posts/intro2r/index.html",
    "title": "A crash course in R programming",
    "section": "",
    "text": "I recently conducted a workshop to teach basic programming in R. It was designed as a crash course for those without coding experience, where we dive right into organising, visualising and analysing data. While it wasn’t meant to be a self-study course, the slides were made to go along with the notes, so anyone should be able to follow along quite nicely. I’ve decided to make the materials freely available on Github.\nCheck out the slides if you’d like to see the potential of the R programming language. I’ve also provided links to useful resources if you’re interested in getting into data science using R."
  },
  {
    "objectID": "posts/intro2r/index.html#workshop-outline",
    "href": "posts/intro2r/index.html#workshop-outline",
    "title": "A crash course in R programming",
    "section": "Workshop outline",
    "text": "Workshop outline\n\nR Environment and Syntax: Notes\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling and Visualisation: Notes\n\n\n\n\n\n\n\n\n\n\n\nThis post is also shared on R-bloggers.com."
  },
  {
    "objectID": "posts/nathans-first-drumset/index.html",
    "href": "posts/nathans-first-drumset/index.html",
    "title": "Nathan’s first drumset",
    "section": "",
    "text": "Sample it before it gets wrecked!"
  },
  {
    "objectID": "posts/photo-classify/index.html",
    "href": "posts/photo-classify/index.html",
    "title": "Automated image classification into content-type categories",
    "section": "",
    "text": "This tutorial describes the workflow and R code that can be used to classify a large number of images into discrete categories, based on their content. The source documents are available on GitHub. This tutorial provides supplementary information to the following publication:\nAn earlier iteration of the code was used in this publication. Note that there are numerous other ways to classify images, including those that deal with overlapping content.\nThe dataset photos is used as an example. It contains 50 photos with a column of photo source URLs. These are sent to the Google Cloud Vision Application Programming Interface (API), to generate up to ten keyword labels per photo.\nNote that you will need to have signed-up with the Google Cloud Platform and generated your Client ID and Client secret. We will be using the googleAuthR and RoogleVision packages to interact with the API.\nFirst few rows of the photos dataset:\nPlug-in your Google Cloud Platform credentials:"
  },
  {
    "objectID": "posts/photo-classify/index.html#A",
    "href": "posts/photo-classify/index.html#A",
    "title": "Automated image classification into content-type categories",
    "section": "A. Distance matrix and clustering",
    "text": "A. Distance matrix and clustering\nExtract all the unique keywords across photos (or subset of photos):\n\nwords <- unlist(photos[,3:12])\nwords <- words[!duplicated(words)] #list of unique keywords\n\n \nNext, we convert photos into a binary format and name it wordscore, with each row representing a photo, and each column representing a keyword. “1” is added if the word is present. We then convert wordscore into a sparse matrix. This will help reduce the load on the computer’s RAM, especially if the photo dataset is very large.\n\n#parallel loop:\nwordscore <- foreach(i = 1:length(photos[,1]), .combine=rbind) %dopar% {\n  vec <- vector(mode = \"integer\",length = length(words))\n  a <- match(photos[i,3:12], words)\n  vec[a] <- 1\n  \n  cat(paste0(\" row \", i), file=paste0(\"admin/log_wordscore.txt\"), append=TRUE) #The loop's progress will be printed in this file\n  vec\n}\ncolnames(wordscore) <- words\nrownames(wordscore) <- NULL\nwordscore <- wordscore[,!is.na(colnames(wordscore))] #remove 'NA' keyword if present\n\nlibrary(Matrix) \nwordscore <- Matrix(wordscore, sparse = TRUE)  #convert to sparseMatrix to save memory\n\n \nIn the binary format, wordscore can now be converted into a distance matrix. To have a fair assessment of the similarity (and thus the distance) between two photos, we need to take into account if they have the same number of keywords generated. The Jaccard Index is used in the calculation, where the number of common keywords is divided by the total number of unique keywords between two photos.\nTo start with, we find out how many keywords each photo has (up to ten), and save the results as the vector lengword:\n\nnarmlength <- function(x){10-sum(is.na(x))} #create function\nlengword <- apply(photos[,3:12], 1, narmlength) #apply function\n\n\n\n\n \nNext, the similarity between each photo and all other photos is calculated manually in a loop, based on the Jaccard Index. Since most photos do not share keywords, the similarity value will tend to be “0” (less strain on computer’s RAM). The similarity matrix (loop output) is then converted into a distance matrix, and subsequently converted into a ‘dist’ object.\n\nsimimat <- foreach(i = 1:length(wordscore[,1]), .packages = \"Matrix\", .combine=cbind) %dopar% {\n  \n  ws <- wordscore[,which(wordscore[i,] == 1)] #for each photo, find the other photos (rows) with its keywords (cols)\n  \n  simi <- round(apply(as.matrix(ws),1,sum, na.rm=T)/(lengword+lengword[i]),2) #Jaccard index\n  \n  simi[1:i] <- 0 #only fill half the matrix\n  simi[i] <- 1\n  \n  cat(paste(\"row\",i), file=paste0(\"admin/log_simimat.txt\"), append=TRUE)\n  \n  simi\n}\n\ncolnames(simimat) <- NULL\nrm(wordscore, lengword)\n\n\n#convert similarity to distance\ndistmat <- 1-simimat\nrm(simimat)\n\n#Convert to a 'dist' object\ndm <- as.dist(distmat)\n\n \nFinally, we perform hierarchical clustering of photos, using Ward’s distance:\n\nrequire(fastcluster)\nrequire(graphics)\n\ncluz <- fastcluster::hclust(dm, \"ward.D2\")\n\n \nGo to ‘B. How many clusters?’ if the number of photo categories has not been determined."
  },
  {
    "objectID": "posts/photo-classify/index.html#B",
    "href": "posts/photo-classify/index.html#B",
    "title": "Automated image classification into content-type categories",
    "section": "B. How many clusters?",
    "text": "B. How many clusters?\nThis section runs as a separate analysis from the final results. Note that the following script may take a long time to run if you have a large dataset.\nIn this analysis, we measure the average difference between within- and between-cluster variation, across different clustering scenarios. Thus, a higher value suggests distinct clusters that are more ‘different’ from each other (i.e. greater variation/distance between clusters). As the number of clusters (k) increases, this value is expected to decrease. We plot these values, and use the L-Method to find the ‘knee’ of the evaluation graph. More information about the L-Method can be found at:\n\nSalvador, S. & Chan, P. Determining the Number of Clusters / Segments in Hierarchical Clustering / Segmentation Algorithms. in 16th IEEE International Conference on Tools with Artificial Intelligence 576-584 (IEEE, 2004). doi:10.1109/ICTAI.2004.50\n\n \nFirst, decide up to how many clusters (k) to test for. In this example, we test k from 2 to 20, and save it as the vector scenarios (19 scenarios):\n\nscenarios <- numeric(length(2:20))\n\n \nCreate a function to measure the difference between within- and between-cluster variation across all photos. Run the function for different k values in scenarios.\n\ndiffer <- function(dist, gr, pos){\n  #dist is a single photo's vector of distances with all others\n  #gr is the vector output of grp membership across all photos\n  #pos is the position of the single photo in length(distmat[1,])\n  \n  gr2 <-numeric(length(gr)) #vector of \"0\"s\n  gr2[gr==gr[pos]] <-1 #Which photos are in same cluster as the photo of interest?\n  gr3 <- 1-tapply(dist,gr2, mean) #2 values generated: (1) mean distance compared to photos in other clusters, & (2) compared to photos within same cluster. Minus values from one to convert to similarity value.\n  gr3[2]-gr3[1] #within-cluster minus between-cluster similarity (larger value means clusters are very different)\n}\n\n\n#Run function for different scenarios (numbers of clusters):\nfor(i in 2:(length(scenarios)+1)){\n  grp <- cutree(cluz, k=i)  #cutree returns vector of grp memberships across all photos\n  \n  cat(\"\\n<< Working on scenario k =\", i, \"/\", (length(scenarios)+1), \">>\\n\")\n  \n  alldiffer <-numeric(length(distmat[,1])) #vector of \"0\"s\"\n  \n  for(j in 1:length(distmat[,1])){ #run function for each photo (across rows)\n    alldiffer[j]<- differ(distmat[j,], grp, j )\n    \n    cat(\"<row\", j, \"/\", length(distmat[,1]), \"photos>\")\n    \n  }\n  scenarios[i-1]<-mean(alldiffer) #find out the mean difference for each scenario (k)\n  \n  cat(\"\\n<< Scenario k =\", i, \"COMPLETE >>\")\n}\n\n\n#Create dataframe\nscenarios <- cbind.data.frame(seq(2,(length(scenarios)+1),1), 1-scenarios) #convert to distance\ncolnames(scenarios) <- c(\"k\", \"distance\")\n\nDo note that the small number of photos in our example produces a relatively straight curve. To help with visualisation, we can also calculate the marginal change in the distance:\n\nfor(i in 2:length(scenarios$distance)){\n  scenarios[i,3] <- scenarios$distance[i-1]-scenarios$distance[i]\n}\n\ncolnames(scenarios) <- c(\"k\",\"distance\",\"marginalDelta\")\n\n\n\n\nHere are plots of the results across different clustering scenarios:\n\n\n\n\n\n\n\nDifferences between within- and between-cluster variation, across different clustering scenarios\n\n\n\n \nSince such plots may not always allow us to visually determine the appropriate number of photo clusters, we can also use the L-Method as described in Salvador and Chan (2004). To do so, we plot possible pairs of best-fit lines to the curve, and calculate the total root mean squared error (RMSE) for each pair. The lowest RMSE value is used to determine the number of clusters.\n\n\n\n\nrequire(rgl)\nrequire(qpcR)\n\n#Best-fit line equation:\nmod1 <- lm(distance ~ k, data = scenarios)\n\n\n#Equation from Salvador & Chan (2004):\nfor(i in 3:(max(scenarios$k)-2)){  #lowest value the 'knee' can be at is 3\n  rmse <-  ((i-1)/(max(scenarios$k)-1)*(RMSE(mod1, which = 2:i))) + (((max(scenarios$k)-i)/(max(scenarios$k)-1))*RMSE(mod1, which = (i+1):max(scenarios$k)))\nscenarios[i-1,4] <- rmse\n}\n\ncolnames(scenarios) <- c(\"k\",\"distance\", \"marginalDelta\", \"Lrmse\")\n\n \nNow we can plot RMSE across an increasing number of clusters (k). In our example, the lowest RMSE value is where k = 11. This is the ‘knee’ of the graph. Note that there are a roughly balanced number of points on either side of this value.\n\n\n\n\n\n\n\nTotal RMSE of possible pairs of best-fit lines\n\n\n\n \nNow it’s time to classify our photos and visualise the categories for good. Go back to ‘A. Distance matrix and clustering’ and re-run the script for the full dataset if a subset of data was used to determine the number of clusters. If not, continue on to the next section…"
  },
  {
    "objectID": "academia.html",
    "href": "academia.html",
    "title": "Academia",
    "section": "",
    "text": "Publications\n\nSong, X. P., Chong, K. Y. (2021). home2park: An R package to assess the spatial provision of urban parks. Journal of Open Source Software, 6(65), 3609. https://doi.org/10.21105/joss.03609\nSong, X. P., Richards, D., Fung, T. K., Drillet, Z., Edwards, P. J. (2021). Design green spaces for people. In Future Cities Laboratory: Indicia 03. Zürich, Lars Müller Publishers.\nFung, T. K., Song, X. P., Richards, D., Leong, R. A. T., Drillet, Z., Edwards, P. J. (2021). Interconnect urban nature. In Future Cities Laboratory: Indicia 03. Zürich, Lars Müller Publishers.\nTeo, H. C., Zeng, Y., Sarira, T. V., Fung, T. K., Zeng, Q., Song, X. P., Chong, K. Y., Koh, L. P. (2021). Global urban reforestation can be an important natural climate solution. Environmental Research Letters, 16, 134059. https://doi.org/10.1088/1748-9326/abe783\nSong, X. P., Lai, H. R., Wijedasa L., Tan, P. Y., Edwards, P. J., Richards, D. R. (2020). Height–diameter allometry for the management of city trees in the tropics. Environmental Research Letters, 15, 114017. https://doi.org/10.1088/1748-9326/abbbad\nSong, X. P., Richards, D. R., He, P. J., Tan, P. Y. (2020). Does geo-located social media reflect the visit frequency of urban parks? A city-wide analysis using the count and content of photographs. Landscape and Urban Planning, 203, 103908. https://doi.org/10.1016/j.landurbplan.2020.103908\nSingapore-ETH Centre Future Cities Laboratory (2020). Ecosystem services in urban landscapes: Benefits of tropical urban vegetation. Available at: https://fcl.ethz.ch/news-events/news/2020/07/benefits-of-tropical-urban-vegetation.html\nTan, P. Y., Zhang, J., Masoudi, M., Alemu, J., Edwards, P. J., Gret-Regamey, A., Richards, D. R. , Saunders, J., Song, X. P., Wong, L. (2020). A conceptual framework to untangle the concept of urban ecosystem services. Landscape and Urban Planning, 20, 103837. https://doi.org/10.1016/j.landurbplan.2020.103837\nChang, Cc., Cheng, G. J. Y., Nghiem, T. P. L., Song, X. P., Oh, R. Y. R., Richards, D. R., Carrasco, L. R. (2020). Social media, nature, and life satisfaction: global evidence of the biophilia hypothesis. Scientific Reports, 10, 4125. https://doi.org/10.1038/s41598-020-60902-w\nSong, X. P., Richards, D. R., Tan, P. Y. (2020). Using social media user attributes to understand human–environment interactions at urban parks. Scientific Reports, 10, 808. https://doi.org/10.1038/s41598-020-57864-4\nChiam, Z., Song, X. P., Lai, H. R., Tan, H. T. W. (2019). Particulate matter mitigation via plants: Understanding complex relationships with leaf traits. Science of The Total Environment, 688, 398–408. https://doi.org/10.1016/j.scitotenv.2019.06.263\nRichards, D. R., Fung, T. K., Meili, N., Song, X. P., Dissegna, A., Drillet, Z. , Urech, P., Edwards, P. J. (2019). An ecosystem service design loop for using vegetation to mitigate the urban heat island effect. In Future Cities Laboratory: Indicia 02. Zürich, Lars Müller Publishers\nSong, X. P., Tan, P. Y., Tan, H. T. W. (2018). Assessment of light adequacy for vertical farming in a tropical city. Urban Forestry & Urban Greening, 29, 49–57. https://doi.org/10.1016/j.ufug.2017.11.004\nSong, X. P., Tan, P. Y., Edwards, P. J., Richards, D. R. (2018). The economic benefits and costs of trees in urban forest stewardship: A systematic review. Urban Forestry & Urban Greening, 29, 162–170. https://doi.org/10.1016/j.ufug.2017.11.017\nSong, X. P., Richards, D. R., Edwards, P. J., Tan, P. Y. (2017). Benefits of trees in tropical cities. Science, 356 (634), 1241. https://doi.org/10.1126/science.aan6642\n\n\n\n\n\nProjects\n\n[Project Manager] Assessment of urban ecosystem services in residential neighbourhoods in Singapore, Cities of Tomorrow R&D Programme (2021). $1.5 million (Principal Investigator: Puay Yok Tan)\n[Project Manager] Development of a biodiversity index for residential towns, Ministry of National Development Research Fund Grant (2016). $1.29 million (Principal Investigator: Kwek Yan Chong)\n[Co-Investigator] Approaching Singapore’s “30 by 30” goal using building-integrated agriculture, Intra-CREATE Seed Collaboration Grant (2021). $249,540\n[Doctoral Researcher] Ecosystem services in urban landscapes, Singapore National Research Foundation (2016). $2.26 million (Principal Investigator: Peter J. Edwards)\n\n\n\n\n\nTeaching\nCourses\n\n[Co-Lecturer] LA5303: Urban Greening Technologies and Techniques. Master of Landscape Architecture, National University of Singapore. Jan–Apr 2020\n\nWorkshops\n\nIntroduction to Git in R. National University of Singapore. Sep 2021, Jul 2022\nIntroduction to R Programming and Statistics. National University of Singapore. Aug 2019, Feb 2020, Sep 2021, Nov 2022\nAnalysing Spatial Patterns of the Landscape. Master of Landscape Architecture, National University of Singapore. Jan 2018, Feb 2020\n\nGuest lectures\n\nEcosystem Services in Landscape Design. Master of Architecture, Taylor’s University. Apr 2019\nSingapore as a Model City: Ecosystem Services in Urban Landscapes. Tembusu College, National University of Singapore. Mar 2018\n\n\n\n\n\nTalks\nConferences / Symposiums\n\n[Presentation] Social media as a tool to understand human interactions with urban nature. 2020 Natural Capital Symposium, San Francisco, USA. Mar 2020\n[Poster] From place to people: Quantifying recreation among park users on social media. British Ecological Society Annual Meeting, Birmingham, UK. Dec 2018\n\nGovernment / Industry\n\n[Invited Presentation] IoT sensor network deployment at public housing estates: Choosing the right mobile communications technology. Singapore Botanic Gardens, National Parks Board. 18 Jan 2023\n[Presentation] Development of a biodiversity index for residential towns using biodiversity field surveys. Research Forum chaired by Singapore government agency HDB. Participating agencies include MND. 12 Dec 2022\n[Invited Presentation] Data-driven approaches to understand human interactions with the environment. 5th Smart Planning SOE Workgroup. Co-chaired by Singapore government agencies URA and HDB, participating agencies include JTC, NParks, LTA, MOH and MND. 15 Nov 2019\n\n\n\n\n\nPeople\n\nZhongyu Chiam. Leaf-level particulate matter deposition on tropical plant species of varying leaf traits. Honours Thesis, BSc Life Sciences. 2017–2018 (Primary Supervisor: Hugh TW Tan)\n\n\n\n\n\nServices\nJournal Reviewer\n\nEnvironmental Research Letters\nLandscape and Urban Planning\nGlobal Ecology and Biogeography\nUrban Forestry and Urban Greening\nLandscape Ecology\nScientific Reports\nPLOS One\nEnvironmental Sustainability"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBiodiversity in cities: How can we assess the ‘performance’ of urban developments?\n\n\nWe need a predictive approach that compares between present and future scenarios\n\n\n\nAug 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNathan’s first drumset\n\n\nSon got his first drumset as a gift… and I had a brainwave\n\n\n\nJan 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrying to fight cabin fever? The types of parks near your home matters\n\n\nWe need better ways to measure our access to parks and outdoor spaces\n\n\n\nJul 16, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChanges in a city’s land cover over time\n\n\nUsing publicly-available satellite data to measure land cover change\n\n\n\nMar 12, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZoom with Drums\n\n\nExploring different ways to set up for online music lessons\n\n\n\nApr 5, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysing spatial patterns of the landscape\n\n\nClassify land cover and quantify landscape configuration\n\n\n\nFeb 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated image classification into content-type categories\n\n\nClassify images based on keywords generated from the Google Cloud Vision API\n\n\n\nJan 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA crash course in R programming\n\n\nFor those without coding experience\n\n\n\nJul 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to clean up ‘tracked changes’ in Word without going insane\n\n\nMicrosoft Word Macro to accept and highlight all tracked changes\n\n\n\nJun 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe performance of city trees\n\n\nDevelop allometric equations for tree size and structure\n\n\n\nApr 1, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‘Kashiwanoha Smart City’ design workshop\n\n\nCollaboration between Tsinghua University, National University of Singapore and Chiba University\n\n\n\nFeb 25, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeasibility of urban farming in compact cities\n\n\nDone with the Honours Thesis!\n\n\n\nApr 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello\n\n\nWell… I finally did it. I started a website. And a blog.\n\n\n\nJan 1, 2016\n\n\n\n\n\n\n\n\nNo matching items"
  }
]